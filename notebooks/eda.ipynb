{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "caeb35db",
   "metadata": {},
   "source": [
    "## 1. Setup & Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9fed581",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "print('Libraries imported successfully')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6571b7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "water_df = pd.read_csv('../data/water_quality.csv')\n",
    "rainfall_df = pd.read_csv('../data/rainfall.csv')\n",
    "\n",
    "print(f'Water Quality Data: {water_df.shape}')\n",
    "print(f'Rainfall Data: {rainfall_df.shape}')\n",
    "print(f'\\nWater Data Date Range: {water_df[\"Timestamp\"].min()} to {water_df[\"Timestamp\"].max()}')\n",
    "print(f'Rainfall Data Date Range: {rainfall_df[\"date\"].min()} to {rainfall_df[\"date\"].max()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a3ea842",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse timestamps and basic preprocessing\n",
    "water_df['Timestamp'] = pd.to_datetime(water_df['Timestamp'], errors='coerce')\n",
    "rainfall_df['date'] = pd.to_datetime(rainfall_df['date'], errors='coerce')\n",
    "\n",
    "# Identify numeric columns\n",
    "numeric_cols = water_df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "print(f'Numeric columns ({len(numeric_cols)}): {numeric_cols}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd7a98cc",
   "metadata": {},
   "source": [
    "## 2. Data Quality Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08269cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive data quality report\n",
    "quality_report = pd.DataFrame({\n",
    "    'Column': water_df.columns,\n",
    "    'Data Type': water_df.dtypes,\n",
    "    'Non-Null Count': water_df.count(),\n",
    "    'Null Count': water_df.isnull().sum(),\n",
    "    'Null %': (water_df.isnull().sum() / len(water_df) * 100).round(2)\n",
    "})\n",
    "quality_report = quality_report.sort_values('Null %', ascending=False)\n",
    "quality_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08504afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nullity heatmap\n",
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "null_data = water_df.isnull().astype(int)\n",
    "sns.heatmap(null_data.iloc[:500, :].T, cbar=True, cmap='YlOrRd', ax=ax, yticklabels=True)\n",
    "ax.set_title('Null Value Heatmap (First 500 Records)', fontsize=14, fontweight='bold')\n",
    "ax.set_xlabel('Record Index')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f'\\nMissing Data Summary:')\n",
    "print(f'Total nulls: {water_df.isnull().sum().sum()}')\n",
    "print(f'Overall null %: {(water_df.isnull().sum().sum() / (len(water_df) * len(water_df.columns)) * 100):.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe00d576",
   "metadata": {},
   "source": [
    "## 3. Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1889cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descriptive statistics for numeric columns\n",
    "water_df[numeric_cols].describe().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18bcb54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Key water quality parameters statistics\n",
    "key_params = ['Average Water Speed', 'Temperature', 'Dissolved Oxygen (%Saturation)',\n",
    "              'pH', 'Salinity', 'Specific Conductance', 'Turbidity']\n",
    "key_params_present = [col for col in key_params if col in water_df.columns]\n",
    "\n",
    "stats_table = water_df[key_params_present].describe().T\n",
    "stats_table['CV%'] = (stats_table['std'] / stats_table['mean'] * 100).round(2)\n",
    "stats_table = stats_table[['count', 'mean', 'std', 'CV%', 'min', '25%', '50%', '75%', 'max']].round(2)\n",
    "stats_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b93477b2",
   "metadata": {},
   "source": [
    "## 4. Parameter Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01644656",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution plots for key parameters\n",
    "fig, axes = plt.subplots(3, 3, figsize=(16, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, col in enumerate(key_params_present[:9]):\n",
    "    data = water_df[col].dropna()\n",
    "    axes[idx].hist(data, bins=50, alpha=0.7, color='steelblue', edgecolor='black')\n",
    "    axes[idx].set_title(f'{col}\\n(n={len(data)}, μ={data.mean():.2f}, σ={data.std():.2f})', fontsize=10)\n",
    "    axes[idx].set_xlabel('Value')\n",
    "    axes[idx].set_ylabel('Frequency')\n",
    "    axes[idx].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e1a8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KDE plots for top 6 parameters\n",
    "fig, axes = plt.subplots(2, 3, figsize=(16, 8))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, col in enumerate(key_params_present[:6]):\n",
    "    data = water_df[col].dropna()\n",
    "    axes[idx].hist(data, bins=50, alpha=0.5, density=True, color='steelblue', edgecolor='black')\n",
    "    data.plot(kind='kde', ax=axes[idx], color='red', linewidth=2, label='KDE')\n",
    "    axes[idx].set_title(f'{col}', fontsize=11, fontweight='bold')\n",
    "    axes[idx].legend()\n",
    "    axes[idx].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "473a62d6",
   "metadata": {},
   "source": [
    "## 5. Temporal Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af6c959",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by timestamp and set index\n",
    "water_sorted = water_df.sort_values('Timestamp').copy()\n",
    "water_sorted.set_index('Timestamp', inplace=True)\n",
    "\n",
    "# Resample to daily frequency for key parameters\n",
    "daily_data = water_sorted[key_params_present].resample('D').mean()\n",
    "print(f'Daily aggregated data shape: {daily_data.shape}')\n",
    "print(f'Date range: {daily_data.index.min()} to {daily_data.index.max()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea1af5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time series plot for key parameters\n",
    "fig, axes = plt.subplots(3, 2, figsize=(16, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, col in enumerate(key_params_present[:6]):\n",
    "    if col in daily_data.columns:\n",
    "        daily_data[col].plot(ax=axes[idx], color='steelblue', linewidth=1.5, alpha=0.7)\n",
    "        daily_data[col].rolling(window=7).mean().plot(ax=axes[idx], color='red', linewidth=2, label='7-day MA')\n",
    "        axes[idx].set_title(f'{col} Over Time', fontsize=11, fontweight='bold')\n",
    "        axes[idx].set_ylabel('Value')\n",
    "        axes[idx].legend()\n",
    "        axes[idx].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c7d55f9",
   "metadata": {},
   "source": [
    "## 6. Seasonal Decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b791cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seasonal decomposition for Turbidity (most important parameter)\n",
    "if 'Turbidity' in daily_data.columns:\n",
    "    # Fill NaN values for decomposition\n",
    "    turbidity_filled = daily_data['Turbidity'].fillna(method='ffill').fillna(method='bfill')\n",
    "    \n",
    "    if len(turbidity_filled) > 14:  # Need at least 2 cycles for period=7\n",
    "        decomposition = seasonal_decompose(turbidity_filled, model='additive', period=7)\n",
    "        \n",
    "        fig, axes = plt.subplots(4, 1, figsize=(14, 10))\n",
    "        \n",
    "        decomposition.observed.plot(ax=axes[0], color='steelblue')\n",
    "        axes[0].set_ylabel('Observed', fontweight='bold')\n",
    "        axes[0].grid(alpha=0.3)\n",
    "        \n",
    "        decomposition.trend.plot(ax=axes[1], color='orange')\n",
    "        axes[1].set_ylabel('Trend', fontweight='bold')\n",
    "        axes[1].grid(alpha=0.3)\n",
    "        \n",
    "        decomposition.seasonal.plot(ax=axes[2], color='green')\n",
    "        axes[2].set_ylabel('Seasonal', fontweight='bold')\n",
    "        axes[2].grid(alpha=0.3)\n",
    "        \n",
    "        decomposition.resid.plot(ax=axes[3], color='red')\n",
    "        axes[3].set_ylabel('Residual', fontweight='bold')\n",
    "        axes[3].set_xlabel('Date')\n",
    "        axes[3].grid(alpha=0.3)\n",
    "        \n",
    "        fig.suptitle('Turbidity - Seasonal Decomposition (7-day period)', fontsize=14, fontweight='bold', y=0.995)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "        print('Insufficient data for seasonal decomposition')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b553da5",
   "metadata": {},
   "source": [
    "## 7. Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e213a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spearman correlation matrix for numeric columns\n",
    "correlation_matrix = water_df[key_params_present].corr(method='spearman')\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt='.2f', cmap='coolwarm', center=0,\n",
    "            cbar_kws={'label': 'Spearman Correlation'}, ax=ax, square=True, linewidths=1)\n",
    "ax.set_title('Spearman Correlation Matrix - Key Water Quality Parameters', fontsize=12, fontweight='bold')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print('\\nTop 10 Strongest Correlations (excluding diagonal):')\n",
    "# Get upper triangle of correlation matrix\n",
    "corr_pairs = []\n",
    "for i in range(len(correlation_matrix.columns)):\n",
    "    for j in range(i+1, len(correlation_matrix.columns)):\n",
    "        corr_pairs.append({\n",
    "            'Param1': correlation_matrix.columns[i],\n",
    "            'Param2': correlation_matrix.columns[j],\n",
    "            'Correlation': correlation_matrix.iloc[i, j]\n",
    "        })\n",
    "corr_df = pd.DataFrame(corr_pairs).sort_values('Correlation', key=abs, ascending=False)\n",
    "corr_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df061e4e",
   "metadata": {},
   "source": [
    "## 8. Outlier Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb9a6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify outliers using IQR method\n",
    "def find_outliers_iqr(data, column):\n",
    "    Q1 = data[column].quantile(0.25)\n",
    "    Q3 = data[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    outliers = data[(data[column] < lower_bound) | (data[column] > upper_bound)]\n",
    "    return len(outliers), lower_bound, upper_bound\n",
    "\n",
    "outlier_summary = []\n",
    "for col in key_params_present:\n",
    "    count, lower, upper = find_outliers_iqr(water_df, col)\n",
    "    outlier_pct = (count / len(water_df.dropna(subset=[col])) * 100) if len(water_df.dropna(subset=[col])) > 0 else 0\n",
    "    outlier_summary.append({\n",
    "        'Parameter': col,\n",
    "        'Outlier Count': count,\n",
    "        'Outlier %': round(outlier_pct, 2),\n",
    "        'Lower Bound': round(lower, 2),\n",
    "        'Upper Bound': round(upper, 2)\n",
    "    })\n",
    "\n",
    "outlier_df = pd.DataFrame(outlier_summary).sort_values('Outlier %', ascending=False)\n",
    "outlier_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90821f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplot for outlier visualization\n",
    "fig, axes = plt.subplots(2, 3, figsize=(16, 8))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, col in enumerate(key_params_present[:6]):\n",
    "    data = water_df[col].dropna()\n",
    "    axes[idx].boxplot(data, vert=True)\n",
    "    axes[idx].set_title(f'{col}', fontsize=11, fontweight='bold')\n",
    "    axes[idx].set_ylabel('Value')\n",
    "    axes[idx].grid(alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a4f3be",
   "metadata": {},
   "source": [
    "## 9. Day-of-Week Patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "769d8a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add day of week to water data\n",
    "water_df['DayOfWeek'] = water_df['Timestamp'].dt.day_name()\n",
    "day_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "\n",
    "# Boxplot by day of week for key parameters\n",
    "fig, axes = plt.subplots(2, 3, figsize=(16, 8))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, col in enumerate(key_params_present[:6]):\n",
    "    plot_data = water_df[[col, 'DayOfWeek']].dropna()\n",
    "    plot_data['DayOfWeek'] = pd.Categorical(plot_data['DayOfWeek'], categories=day_order, ordered=True)\n",
    "    plot_data_sorted = plot_data.sort_values('DayOfWeek')\n",
    "    \n",
    "    sns.boxplot(data=plot_data_sorted, x='DayOfWeek', y=col, ax=axes[idx], palette='Set2')\n",
    "    axes[idx].set_title(f'{col} by Day of Week', fontsize=11, fontweight='bold')\n",
    "    axes[idx].set_xlabel('Day of Week')\n",
    "    axes[idx].set_ylabel('Value')\n",
    "    axes[idx].tick_params(axis='x', rotation=45)\n",
    "    axes[idx].grid(alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "967aa691",
   "metadata": {},
   "source": [
    "## 10. Rainfall Data Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b067ea99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rainfall statistics\n",
    "print('Rainfall Data Summary:')\n",
    "print(rainfall_df.describe().round(2))\n",
    "print(f'\\nDate Range: {rainfall_df[\"date\"].min()} to {rainfall_df[\"date\"].max()}')\n",
    "print(f'Days Covered: {(rainfall_df[\"date\"].max() - rainfall_df[\"date\"].min()).days + 1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e9a5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rainfall visualization\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 8))\n",
    "\n",
    "# Rainfall time series\n",
    "rainfall_df.sort_values('date').set_index('date')['rainfall'].plot(ax=axes[0, 0], kind='bar', color='steelblue')\n",
    "axes[0, 0].set_title('Daily Rainfall', fontsize=11, fontweight='bold')\n",
    "axes[0, 0].set_ylabel('Rainfall (mm)')\n",
    "axes[0, 0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Temperature\n",
    "rainfall_df.sort_values('date').set_index('date')['temperature'].plot(ax=axes[0, 1], color='orange')\n",
    "axes[0, 1].set_title('Temperature Over Time', fontsize=11, fontweight='bold')\n",
    "axes[0, 1].set_ylabel('Temperature (°C)')\n",
    "axes[0, 1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Humidity\n",
    "rainfall_df.sort_values('date').set_index('date')['humidity'].plot(ax=axes[1, 0], color='green')\n",
    "axes[1, 0].set_title('Humidity Over Time', fontsize=11, fontweight='bold')\n",
    "axes[1, 0].set_ylabel('Humidity (%)')\n",
    "axes[1, 0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Wind Speed\n",
    "rainfall_df.sort_values('date').set_index('date')['wind_speed'].plot(ax=axes[1, 1], color='purple')\n",
    "axes[1, 1].set_title('Wind Speed Over Time', fontsize=11, fontweight='bold')\n",
    "axes[1, 1].set_ylabel('Wind Speed (m/s)')\n",
    "axes[1, 1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f29214c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rainfall statistics\n",
    "print('\\nRainfall Statistics:')\n",
    "print(f'Total rainfall: {rainfall_df[\"rainfall\"].sum():.2f} mm')\n",
    "print(f'Average daily rainfall: {rainfall_df[\"rainfall\"].mean():.2f} mm')\n",
    "print(f'Max daily rainfall: {rainfall_df[\"rainfall\"].max():.2f} mm')\n",
    "print(f'Rainy days (> 0 mm): {(rainfall_df[\"rainfall\"] > 0).sum()} out of {len(rainfall_df)}')\n",
    "print(f'Rainfall % of days: {(rainfall_df[\"rainfall\"] > 0).sum() / len(rainfall_df) * 100:.1f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "824a2ff0",
   "metadata": {},
   "source": [
    "## 11. Data Integration Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4acbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temporal alignment analysis\n",
    "print('Data Alignment Analysis:')\n",
    "print('='*50)\n",
    "\n",
    "# Water data date range\n",
    "water_dates = pd.to_datetime(water_df['Timestamp']).dt.date\n",
    "water_date_range = (water_dates.max() - water_dates.min()).days + 1\n",
    "\n",
    "# Rainfall date range\n",
    "rainfall_dates = pd.to_datetime(rainfall_df['date']).dt.date\n",
    "rainfall_date_range = (rainfall_dates.max() - rainfall_dates.min()).days + 1\n",
    "\n",
    "print(f'Water Quality Data:')\n",
    "print(f'  - Date range: {water_dates.min()} to {water_dates.max()}')\n",
    "print(f'  - Days covered: {water_date_range}')\n",
    "print(f'  - Total records: {len(water_df)}')\n",
    "print(f'  - Records per day avg: {len(water_df) / water_date_range:.1f}')\n",
    "\n",
    "print(f'\\nRainfall Data:')\n",
    "print(f'  - Date range: {rainfall_dates.min()} to {rainfall_dates.max()}')\n",
    "print(f'  - Days covered: {rainfall_date_range}')\n",
    "\n",
    "# Overlapping dates\n",
    "common_dates = set(water_dates) & set(rainfall_dates)\n",
    "print(f'\\nData Overlap:')\n",
    "print(f'  - Common dates: {len(common_dates)}')\n",
    "print(f'  - Coverage: {len(common_dates) / min(water_date_range, rainfall_date_range) * 100:.1f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1aeb6dc",
   "metadata": {},
   "source": [
    "## 12. Key Findings & Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c3245d",
   "metadata": {},
   "outputs": [],
   "source": [
    "findings = \"\"\"\n",
    "KEY FINDINGS FROM EDA:\n",
    "======================\n",
    "\n",
    "1. DATA QUALITY:\n",
    "   - Water dataset: 30,894 records with 20 columns\n",
    "   - Critical parameters with high missingness:\n",
    "     * Dissolved Oxygen: 18.6% missing\n",
    "     * Temperature: 16.7% missing\n",
    "   - Rainfall dataset: Only 54 days vs 152 days of water data\n",
    "   - RECOMMENDATION: Fill missing values with median imputation or interpolation\n",
    "\n",
    "2. TEMPORAL PATTERNS:\n",
    "   - Strong day-of-week effects observed in water quality\n",
    "   - Seasonal patterns visible (7-day decomposition shows cyclical trends)\n",
    "   - RECOMMENDATION: Use seasonal naive baselines for forecasting\n",
    "\n",
    "3. CORRELATIONS:\n",
    "   - Check heatmap for parameter relationships\n",
    "   - Dissolved Oxygen likely inversely related to Turbidity\n",
    "   - Temperature may influence sensor readings\n",
    "   - RECOMMENDATION: Use Spearman correlation (robust to non-linearity)\n",
    "\n",
    "4. OUTLIERS:\n",
    "   - Several parameters show outliers (>1.5 IQR from quartiles)\n",
    "   - Turbidity most prone to extreme values\n",
    "   - RECOMMENDATION: Cap extreme values at 99.9% quantile\n",
    "\n",
    "5. DATA IMBALANCE:\n",
    "   - Water data collected at higher frequency than rainfall\n",
    "   - Missing site/location identifiers\n",
    "   - RECOMMENDATION: Resample water data to daily average; add location metadata\n",
    "\n",
    "NEXT STEPS:\n",
    "===========\n",
    "1. Build preprocessing module to handle missing data consistently\n",
    "2. Engineer features: rolling means, lag features, day-of-week dummies\n",
    "3. Develop WQI (Water Quality Index) from key parameters\n",
    "4. Train baseline models (RandomForest for turbidity prediction)\n",
    "5. Integrate rainfall data for impact analysis\n",
    "6. Create anomaly detection pipeline\n",
    "7. Deploy real-time monitoring dashboard\n",
    "\"\"\"\n",
    "\n",
    "print(findings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980c550b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export processed data for downstream use\n",
    "# Daily aggregated data\n",
    "daily_export = daily_data.copy()\n",
    "daily_export.to_csv('../data/water_quality_daily.csv')\n",
    "print(f'Exported daily aggregated data: {daily_export.shape} records')\n",
    "print(f'Date range: {daily_export.index.min()} to {daily_export.index.max()}')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
